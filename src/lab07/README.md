# –õ–†7 ‚Äî –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: pytest + —Å—Ç–∏–ª—å (black)

## A. –¢–µ—Å—Ç—ã –¥–ª—è `src/lib/text.py`

```python
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),
        ("     ", ""),
    ],
)
def test_normalize(source, expected):
    assert normalize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
        ("", []),
    ],
)
def test_tokenize(source, expected):
    assert tokenize(source) == expected


def test_count_freq_and_top_n():
    tokens = ["a", "b", "a", "c", "b", "a"]
    freq = count_freq(tokens)
    assert freq == {"a": 3, "b": 2, "c": 1}
    top = top_n(freq, 2)
    assert top == [("a", 3), ("b", 2)]


def test_top_n_tie_breaker():
    freq = {"apple": 2, "banana": 2, "cherry": 1}
    top = top_n(freq, 2)
    assert top == [("apple", 2), ("banana", 2)]
```

## B. –¢–µ—Å—Ç—ã –¥–ª—è `src/lab05/json_csv.py`

```python
import pytest
import json
import csv
from pathlib import Path
from src.lab05.json_csv import json_to_csv, csv_to_json


def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())


def test_csv_to_json_roundtrip(tmp_path: Path):
    csv_file = tmp_path / "people.csv"
    json_file = tmp_path / "people.json"
    data = [
        {"name": "Alice", "age": "22"},
        {"name": "Bob", "age": "25"},
    ]
    with csv_file.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()
        writer.writerows(data)

    csv_to_json(str(csv_file), str(json_file))

    with json_file.open(encoding="utf-8") as f:
        loaded = json.load(f)

    assert loaded == data


@pytest.mark.parametrize("bad_file", ["", "notjson.txt"])
def test_json_to_csv_invalid_file(tmp_path: Path, bad_file):
    path = tmp_path / bad_file
    with pytest.raises((ValueError, FileNotFoundError)):
        json_to_csv(str(path), str(tmp_path / "out.csv"))


@pytest.mark.parametrize("bad_file", ["", "notcsv.txt"])
def test_csv_to_json_invalid_file(tmp_path: Path, bad_file):
    path = tmp_path / bad_file
    with pytest.raises((ValueError, FileNotFoundError)):
        csv_to_json(str(path), str(tmp_path / "out.json"))
```

### –ê–≤—Ç–æ—Ç–µ—Å—Ç

![image7.1](../../images/lab07/an_pytest.png)

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è black

![image7.2](../../images/lab07/black-check.png)


